{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NopJ0hY5u6vj"
      },
      "source": [
        "The goal here is to build a FSQ-VAE which builds latent vectors for spatio-temporal \"tublets\" described in the ViViT. Sequences of tublet latent vectors are to then be modeled by a Transformer Decoder\n",
        "\n",
        "![](https://i.imgur.com/9G7QTfV.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hXn2eB7nRgLD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R5vTjhRoTi5o"
      },
      "outputs": [],
      "source": [
        "# I want to take a video tensor of shape (B, C, T, H, W) and split it into\n",
        "# patches of shape (t, p, p) aka \"tubelets\", but instead of performing a single\n",
        "# Conv3d operation on them such that the tublet dims are the kernel dims, I want\n",
        "# to have tublets be the input to a small VAE so that the resulting latents\n",
        "# can be mapped back to pixel space\n",
        "\n",
        "# video dimensions\n",
        "B, C, T, H, W = 4, 3, 64, 256, 256\n",
        "\n",
        "# patch dim\n",
        "t, p = 8, 16\n",
        "\n",
        "assert T % t == 0\n",
        "assert H % p == 0\n",
        "assert W % p == 0\n",
        "\n",
        "n_t, n_h, n_w = T // t, H // p, W // p\n",
        "\n",
        "vid = torch.randn(B, C, T, H, W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (B, C, T, H, W) -> (B, C, n_t, t, n_h, p, n_w, p)\n",
        "tubelets = vid.reshape(B, C, n_t, t, n_h, p, n_w, p)\n",
        "print(tubelets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (B, C, n_t, t, n_h, p, n_w, p) -> (B, n_t, n_h, n_w, C, t, p, p)\n",
        "tubelets = tubelets.permute(0, 2, 4, 6, 1, 3, 5, 7).contiguous()\n",
        "print(tubelets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (B, n_t, n_h, n_w, C, t, p, p) -> ((B * n_t * n_h * n_w), C, t, p, p)\n",
        "tubelets = tubelets.reshape(-1, C, t, p, p)\n",
        "print(tubelets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv3d_1 = nn.Conv3d(in_channels=C, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
        "out1 = conv3d_1(tubelets)\n",
        "print(out1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv3d_2 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
        "out2 = conv3d_2(out1)\n",
        "print(out2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv3d_3 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
        "out3 = conv3d_3(out2)\n",
        "print(out3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv3d_4 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3, stride=(1, 2, 2), padding=1)\n",
        "out4 = conv3d_4(out3)\n",
        "print(out4.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
