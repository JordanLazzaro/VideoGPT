{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The goal here is to build a FSQ-VAE which builds latent vectors for spatio-temporal \"tublets\" described in the ViViT. Sequences of tublet latent vectors are to then be modeled by a Transformer Decoder\n",
        "\n",
        "![](https://i.imgur.com/9G7QTfV.png)"
      ],
      "metadata": {
        "id": "NopJ0hY5u6vj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hXn2eB7nRgLD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to take a video tensor of shape (B, C, T, H, W) and split it into\n",
        "# patches of shape (t, p, p) aka \"tubelets\", but instead of performing a single\n",
        "# Conv3d operation on them such that the tublet dims are the kernel dims, I want\n",
        "# to have tublets be the input to a small VAE so that the resulting latents\n",
        "# can be mapped back to pixel space\n",
        "\n",
        "# video dimensions\n",
        "B, C, T, H, W = 4, 3, 64, 256, 256\n",
        "\n",
        "# patch dim\n",
        "p = 16\n",
        "t = 4\n",
        "\n",
        "vid = torch.randn(B, C, T, H, W)"
      ],
      "metadata": {
        "id": "R5vTjhRoTi5o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to take a\n",
        "vid_unfolded_h = vid.unfold(3, p, p)\n",
        "print(vid_unfolded_h.shape)\n",
        "vid_unfolded_wh = vid_unfolded_h.unfold(4, p, p)\n",
        "print(vid_unfolded_wh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKN5YZ1Y80EB",
        "outputId": "c529752d-8141-4999-931c-6365b50dac91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 64, 16, 256, 16])\n",
            "torch.Size([4, 3, 64, 16, 16, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vid_patch_seq = vid_unfolded_wh.reshape(B, C, T, -1, p, p)"
      ],
      "metadata": {
        "id": "sjH_T4WaQ6P8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vid_patch_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiepPfDPRRK9",
        "outputId": "b3b2959e-9056-4726-a92d-046d55ff7616"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 64, 256, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vid_patch_seq = vid_patch_seq.permute(0, 3, 1, 2, 4, 5).contiguous()\n",
        "print(vid_patch_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erNSQIuTRrM6",
        "outputId": "c50e5797-4333-4abc-9618-6b1e183e2b07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256, 3, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vid_patch_seq = vid_patch_seq.view(-1, C, T, p, p)\n",
        "print(vid_patch_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmA79WmnR-0p",
        "outputId": "e0e9d076-1abd-41bf-afd7-249b8111eb70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1024, 3, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: I'm no sure this is correct, I want a sequence of tubelets\n",
        "# like the illustration, ie. cat([x_1, x_k], [x_k+1, x_j], ...)\n",
        "vid_patch_seq = vid_patch_seq.unfold(2, t, t)\n",
        "print(vid_patch_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOPnC2-UStcO",
        "outputId": "3f7cbc56-6013-4f7d-b5b8-c64c586e1660"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1024, 3, 16, 16, 16, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv3d_1 = nn.Conv3d(in_channels=C, out_channels=32, kernel_size=(t, p, p), stride=2, padding=1)\n",
        "out1 = conv3d_1(vid)\n",
        "print(out1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZsGOZXAyr-T",
        "outputId": "fea1225d-5dca-4215-fa6f-3363901e5b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 16, 126, 126])\n"
          ]
        }
      ]
    }
  ]
}