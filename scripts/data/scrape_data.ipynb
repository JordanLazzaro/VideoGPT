{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMEBOY_LP_URL = 'https://longplays.org/infusions/longplays/longplays.php?cat_id=30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import httpx\n",
    "from urllib.parse import urlparse, unquote\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from urllib.parse import urlparse\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape for Longplay URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_site(url, selector='table'):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.firefox.launch()\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        await page.wait_for_selector(selector)\n",
    "        content = await page.inner_html(selector)\n",
    "        await browser.close()\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = await scrape_site(GAMEBOY_LP_URL, selector='tbody')\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "longplays = [{'name': link.text, 'url': urljoin(GAMEBOY_LP_URL, link.get('href'))} for link in links if 'longplay_id=' in link.get('href')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_longplays(longplays, max_concurrent=3, wait_for_selector='table.tblDetail'):\n",
    "    ''' assuming longplays: [{ 'name': '', url: '' }, ...]'''\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.firefox.launch()\n",
    "        semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        data = []\n",
    "        \n",
    "        async def scrape_longplay(longplay):\n",
    "            async with semaphore:\n",
    "                await asyncio.sleep(random.uniform(1, 3))\n",
    "                page = await browser.new_page()\n",
    "                try:\n",
    "                    # get page content\n",
    "                    await page.goto(longplay['url'])\n",
    "                    await page.wait_for_selector(wait_for_selector)\n",
    "                    content = await page.content()\n",
    "                    await page.close()\n",
    "                    \n",
    "                    # extract and store longplay metadata\n",
    "                    soup = BeautifulSoup(content, 'html.parser')\n",
    "                    authors_ = soup.find_all('a', href=lambda x: x and 'author=' in x)\n",
    "                    download_links_ = soup.find_all('a', href=lambda x: x and 'file_id=' in x)\n",
    "                    file_size_ = soup.find(string=re.compile(r'\\d+\\.\\d+\\s*MB'))\n",
    "\n",
    "                    authors = [{'username': link.text, 'url': urljoin(GAMEBOY_LP_URL, link.get('href'))} for link in authors_]\n",
    "                    download_links = [urljoin(GAMEBOY_LP_URL, link.get('href')) for link in download_links_]\n",
    "                    file_size = file_size_.text\n",
    "                    \n",
    "                    data.append({\n",
    "                        'name': longplay['name'],\n",
    "                        'authors': authors,\n",
    "                        'downloads': download_links,\n",
    "                        'file_size': file_size\n",
    "                    })\n",
    "                    # return url, BeautifulSoup(content, 'html.parser')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping {longplay['url']}: {e}\")\n",
    "                    await page.close()\n",
    "                    return None\n",
    "\n",
    "        await tqdm_asyncio.gather(\n",
    "            *[scrape_longplay(longplay) for longplay in longplays],\n",
    "            desc=\"Scraping sites\",\n",
    "            total=len(longplays)\n",
    "        )\n",
    "        \n",
    "        await browser.close()\n",
    "        return { 'longplays': data }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping sites: 100%|██████████| 489/489 [14:09<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "results = await scrape_longplays(longplays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Longplay Download Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/VideoGen\n"
     ]
    }
   ],
   "source": [
    "%cd VideoGen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/longplay_metadata.json', 'r') as f:\n",
    "    lp_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for lp in lp_data['longplays']:\n",
    "    c += len(lp['archive_links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_actual_download_url(initial_url):\n",
    "    async with async_playwright() as p:\n",
    "        browser = None\n",
    "        try:\n",
    "            browser = await p.firefox.launch(headless=True)\n",
    "            context = await browser.new_context()\n",
    "            page = await context.new_page()\n",
    "            \n",
    "            download_url = None\n",
    "            \n",
    "            async def handle_download(download):\n",
    "                nonlocal download_url\n",
    "                download_url = download.url\n",
    "                await download.cancel()\n",
    "            \n",
    "            page.on('download', handle_download)\n",
    "            \n",
    "            try:\n",
    "                await page.goto(initial_url)\n",
    "            except Exception as e:\n",
    "                # Only log error if we didn't get a download URL\n",
    "                if not download_url:\n",
    "                    print(f\"Error: {e}\")\n",
    "                \n",
    "            if download_url:\n",
    "                return download_url\n",
    "            return page.url\n",
    "            \n",
    "        finally:\n",
    "            if browser:\n",
    "                await browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = await get_actual_download_url(\"https://longplays.org/infusions/longplays/longplays.php?file_id=11829\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ia804503.us.archive.org/10/items/game-boy-longplay-rockman-world-3-jp/Game_Boy_Longplay_-_Rockman_World_3_-_JP.mkv'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lp in lp_data['longplays']:\n",
    "    if lp['id'] == 404:\n",
    "        lp['archive_links'] = [ url ]\n",
    "        # print(lp['archive_links'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/longplay_metadata.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(lp_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lp in lp_data['longplays']:\n",
    "    urls = []\n",
    "    for idx, dl_url in enumerate(lp['downloads']):\n",
    "        print(f'getting archive link {idx} for {lp}')\n",
    "        urls.append(await get_actual_download_url(dl_url))\n",
    "    lp['archive_links'] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lp in lp_data['longplays']:\n",
    "    if len(lp['archive_links']) == 0:\n",
    "        print(lp['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('VideoGen/data/longplay_metadata.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(lp_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_file(path: str) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Verify if a file downloaded correctly\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(path):\n",
    "            return False, \"File does not exist\"\n",
    "            \n",
    "        # Check if file is empty\n",
    "        if os.path.getsize(path) == 0:\n",
    "            return False, \"Empty file (0 bytes)\"\n",
    "            \n",
    "        # Try to read the file to check if it's corrupted\n",
    "        with open(path, 'rb') as f:\n",
    "            # Read first and last kb to verify file is readable\n",
    "            f.read(1024)\n",
    "            f.seek(-1024, 2)\n",
    "            f.read()\n",
    "        \n",
    "        return True, \"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, f\"Verification failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_file(url: str, semaphore, idx: int, url_idx: int, download_dir: str = \".\") -> tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    Download a file and verify its integrity\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (output_path, is_valid, error_message)\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            try:\n",
    "                async with client.stream(\"GET\", url) as response:\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    if 'content-disposition' in response.headers:\n",
    "                        cd = response.headers['content-disposition']\n",
    "                        filename = cd.split('filename=')[-1].strip('\"')\n",
    "                    else:\n",
    "                        filename = unquote(os.path.basename(urlparse(url).path))\n",
    "                        if not filename:\n",
    "                            filename = \"download\"\n",
    "                    \n",
    "                    output_path = os.path.join(download_dir, str(idx) + '_' + str(url_idx) + '_' + filename)\n",
    "                    \n",
    "                    if os.path.exists(output_path):\n",
    "                        is_valid, error_msg = await verify_file(output_path)\n",
    "                        return output_path, is_valid, error_msg\n",
    "                    \n",
    "                    with open(output_path, 'wb') as file:\n",
    "                        async for chunk in response.aiter_bytes():\n",
    "                            file.write(chunk)\n",
    "                    \n",
    "                    # Verify the downloaded file\n",
    "                    is_valid, error_msg = await verify_file(output_path)\n",
    "                    return output_path, is_valid, error_msg\n",
    "                    \n",
    "            except Exception as e:\n",
    "                return \"\", False, f\"Download failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_files(urls, download_dir='gameboy_longplays'):\n",
    "    ''' urls: [..., (longplay id, [..., url, ...]), ... ] '''\n",
    "    semaphore = asyncio.Semaphore(10)\n",
    "    total_urls = len(urls)\n",
    "    failed_downloads = []\n",
    "    \n",
    "    pbar = tqdm(total=total_urls, desc=\"Downloading files\")\n",
    "    \n",
    "    try:\n",
    "        async def download_with_progress(url, idx, url_idx):\n",
    "            result = await download_file(url, semaphore, idx, url_idx, download_dir)\n",
    "            pbar.update(1)\n",
    "            return (url, *result)  # Include the URL in the result tuple\n",
    "        \n",
    "        tasks = []\n",
    "        for idx, url_list in urls:\n",
    "            for url_idx, url in enumerate(url_list):\n",
    "                task = asyncio.create_task(download_with_progress(url, idx, url_idx))\n",
    "                tasks.append(task)\n",
    "        \n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        for result in results:\n",
    "            if isinstance(result, Exception):\n",
    "                # Handle any exceptions that occurred during download\n",
    "                print(f\"Error during download: {result}\")\n",
    "                continue\n",
    "                \n",
    "            url, path, is_valid, error_msg = result\n",
    "            if not is_valid:\n",
    "                failed_downloads.append((url, path, error_msg))\n",
    "    \n",
    "    finally:\n",
    "        pbar.close()\n",
    "    \n",
    "    # Report any failed downloads\n",
    "    if failed_downloads:\n",
    "        print(\"\\nFailed downloads:\")\n",
    "        for url, path, error in failed_downloads:\n",
    "            print(f\"- URL: {url}\")\n",
    "            print(f\"  Path: {path}\")\n",
    "            print(f\"  Error: {error}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"\\nAll files downloaded and verified successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for lp in lp_data['longplays']:\n",
    "    urls.append((lp['id'], lp['archive_links']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for url in urls:\n",
    "    count += len(url[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  config  notebooks\t     scripts   videogen\n",
      "assets\t   data    requirements.txt  setup.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lps = {}\n",
    "for file in Path('data/gameboy_longplays').glob('*'):\n",
    "    name = file.name.split('_')\n",
    "    idx, url_idx = name[0], name[1]\n",
    "    if idx not in lps:\n",
    "        lps[idx] = [ url_idx ]\n",
    "    else:\n",
    "        lps[idx].append(url_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([len(urls) for urls in lps.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lps_true = {}\n",
    "for lp in lp_data['longplays']:\n",
    "    lps_true[lp['id']] = lp['archive_links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ia601200.us.archive.org/32/items/Longplays_ScHlAuChi_December_2023/Game_Boy_Longplay_-_Genesis_-_US_-_UL.mkv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lps_true[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360: 0 / 1\n",
      "376: 0 / 1\n"
     ]
    }
   ],
   "source": [
    "for (idx, urls) in lps_true.items():\n",
    "    if str(idx) not in lps:\n",
    "        print(f'{idx}: 0 / {len(lps_true[idx])}')\n",
    "    elif len(lps[str(idx)]) != len(lps_true[idx]):\n",
    "        print(f'{idx}: {len(lps[str(idx)])} / {len(lps_true[idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    (360, [\"https://dn720309.ca.archive.org/0/items/game-boy-longplay-last-action-hero-us/Game_Boy_Longplay_-_Last_Action_Hero_-_US.mkv\"]),\n",
    "    (376, [\"https://dn720309.ca.archive.org/0/items/Game_Boy_Longplay_-_The_Adventures_of_Tintin_-_Prisoners_of_the_Sun_-_EU/Game_Boy_Longplay_-_The_Adventures_of_Tintin_-_Prisoners_of_the_Sun_-_EU.mkv\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed downloads:\n",
      "- URL: https://dn720309.ca.archive.org/0/items/game-boy-longplay-last-action-hero-us/Game_Boy_Longplay_-_Last_Action_Hero_-_US.mkv\n",
      "  Path: \n",
      "  Error: Download failed: object tuple can't be used in 'await' expression\n",
      "\n",
      "- URL: https://dn720309.ca.archive.org/0/items/Game_Boy_Longplay_-_The_Adventures_of_Tintin_-_Prisoners_of_the_Sun_-_EU/Game_Boy_Longplay_-_The_Adventures_of_Tintin_-_Prisoners_of_the_Sun_-_EU.mkv\n",
      "  Path: \n",
      "  Error: Download failed: object tuple can't be used in 'await' expression\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "await download_files(urls, download_dir='data/gameboy_longplays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Getaway: about:blank\n",
      "Kirby's Dream Land 2: about:blank\n",
      "Super Mario 4 (Unlicensed): about:blank\n",
      "Rockman World 3: about:blank\n"
     ]
    }
   ],
   "source": [
    "for lp in lp_data['longplays']:\n",
    "    for link in lp['archive_links']:\n",
    "        if 'https://' not in link and 'http://' not in link:\n",
    "            print(f\"{lp['name']}: {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_files(url_dict, download_dir='gameboy_longplays'):\n",
    "    semaphore = asyncio.Semaphore(10)\n",
    "    total_urls = sum(len(url_list) for url_list in url_dict.values())\n",
    "    \n",
    "    with tqdm(total=total_urls, desc=\"Downloading files\") as pbar:\n",
    "        tasks = []\n",
    "        for idx, url_list in url_dict.items():\n",
    "            for url_idx, url in enumerate(url_list):\n",
    "                task = asyncio.create_task(download_file(url, semaphore, idx, url_idx, download_dir))\n",
    "                task.add_done_callback(lambda _: pbar.update(1))\n",
    "                tasks.append(task)\n",
    "        \n",
    "        await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/VideoGen\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about:blank\n"
     ]
    }
   ],
   "source": [
    "semaphore = asyncio.Semaphore(10)\n",
    "for url_idx, u in enumerate(urls[138]):\n",
    "    print(u)\n",
    "    # await download_file(u, semaphore=semaphore, idx=138, url_idx=url_idx, download_dir='data/gameboy_longplays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await download_files(url_dict=urls, download_dir='data/gameboy_longplays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "def check_downloads(directory):\n",
    "    issues = []\n",
    "    \n",
    "    for path in Path(directory).iterdir():\n",
    "        if not path.is_file():\n",
    "            continue\n",
    "            \n",
    "        # Check if file is empty\n",
    "        if path.stat().st_size == 0:\n",
    "            issues.append(f\"{path.name}: Empty file (0 bytes)\")\n",
    "            continue\n",
    "            \n",
    "        # Try to read the file to check if it's corrupted\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                # Read first and last kb to verify file is readable\n",
    "                f.read(1024)\n",
    "                f.seek(-1024, 2)\n",
    "                f.read()\n",
    "                \n",
    "            # Optional: Calculate file hash\n",
    "            # md5 = hashlib.md5()\n",
    "            # with open(path, 'rb') as f:\n",
    "            #     for chunk in iter(lambda: f.read(4096), b''):\n",
    "            #         md5.update(chunk)\n",
    "            # print(f\"{path.name}: {md5.hexdigest()}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            issues.append(f\"{path.name}: Possible corruption - {str(e)}\")\n",
    "    \n",
    "    return issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_downloads('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to MP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_names = {}\n",
    "for lp in lp_data['longplays']:\n",
    "    id_names[lp['id']] = f\"{lp['id']}_{lp['name'].replace(' ','_')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0_Star_Wars', 1: '1_Donkey_Kong_Land_III', 2: '2_Elevator_Action', 3: '3_Zettai_Muteki_Raijin-oh', 4: '4_Uoozu', 5: '5_Rubble_Saver_II', 6: '6_Rubble_Saver', 7: '7_Game_Boy_Gallery_2', 8: \"8_Milon's_Secret_Castle\", 9: '9_Game_Boy_Gallery_(JP)', 10: '10_Penguin-kun_Wars_VS.', 11: '11_Oddworld_Adventures', 12: '12_King_of_the_Zoo', 13: '13_Arcade_Classic_No._2:_Centipede_/_Millipede', 14: '14_Arcade_Classic_No._3:_Galaga_/_Galaxian', 15: '15_Arcade_Classic_No._1:_Asteroids_/_Missile_Command', 16: '16_Jimmy_Connors_no_Pro_Tennis_Tour', 17: '17_Yannick_Noah_Tennis', 18: '18_In_Your_Face', 19: '19_TrailBlazers:_Death_Track_(Prototype_/_No_Audio)', 20: '20_Wing_Warriors_(Homebrew)', 21: '21_Bomberman_GB', 22: '22_Atomic_Punk', 23: '23_The_Jetsons:_Robot_Panic', 24: '24_A-Force:_Armour_Force_(Unlicensed)', 25: '25_Arcade_Classics:_Breakout_&_Battlezone', 26: '26_Jimmy_Connors_Tennis', 27: '27_Track_Meet:_Mezase!_Barcelona', 28: '28_Power_Racer', 29: \"29_Mario's_Picross\", 30: '30_Spartan_X', 31: '31_Puyo_Puyo', 32: '32_Tip_Off', 33: '33_Track_Meet', 34: '34_Konamic_Sports_in_Barcelona', 35: '35_Hyper_Dunk', 36: '36_Track_&_Field', 37: '37_GB_Basketball', 38: '38_Double_Dribble:_5_on_5', 39: '39_Konamic_Basket', 40: '40_Konamic_Ice_Hockey', 41: '41_World_Ice_Hockey', 42: '42_Zoo_Block_(Unlicensed)', 43: '43_Shanghai', 44: '44_The_Ren_&_Stimpy_Show:_Veediots!', 45: '45_Caesars_Palace', 46: '46_Blades_of_Steel', 47: '47_Sneaky_Snakes', 48: '48_Barbie:_Game_Girl', 49: '49_Hit_the_Ice', 50: \"50_NHL_Hockey_'95\", 51: \"51_NHL_'96\", 52: '52_Noobow_(Fan_Translation)', 53: '53_Bikkuri_Nekketsu_Shin_Kiroku!:_Dokodemo_Kin_Medal', 54: '54_Nekketsu_Koukou_Dodge_Ball-bu', 55: '55_Nekketsu_Kouha_Kunio-kun:_Bangai_Rantou_Hen', 56: '56_Nekketsu!_Beach_Volley_dayo_Kunio-kun', 57: '57_Nekketsu_Koukou_Soccer-bu:_World_Cup_Hen', 58: '58_Zettai_Muteki_Raijin-oh_(Fan_Translation)', 59: '59_Nintendo_World_Cup', 60: '60_Attack_of_the_Killer_Tomatoes', 61: '61_Alien_3', 62: '62_Zen:_Intergalactic_Ninja', 63: \"63_FIFA_Soccer_'97\", 64: '64_Trax', 65: \"65_FIFA:_Road_to_World_Cup_'98\", 66: '66_FIFA_International_Soccer', 67: \"67_FIFA_Soccer_'96\", 68: '68_Burger_Time_Deluxe', 69: '69_Genjin_Cottsu', 70: '70_Dexterity', 71: '71_Boulder_Dash', 72: '72_Chalvo_55_-_Super_Puzzle_Action', 73: '73_Super_Donkey_Kong_3_(Unlicensed)', 74: '74_The_Adventures_of_Rocky_and_Bullwinkle_and_Friends', 75: '75_Jeopardy!:_Sports_Edition', 76: '76_Jeopardy!:_Platinum_Edition', 77: '77_Jeopardy!:_Teen_Tournament', 78: '78_Jeopardy!', 79: '79_Wheel_of_Fortune', 80: '80_Minesweeper', 81: '81_Flipull:_An_Exciting_Cube_Game', 82: '82_Side_Pocket', 83: '83_Arcade_Classic_No._4:_Defender/Joust', 84: '84_Batman_Forever', 85: '85_The_Smurfs:_Travel_the_World', 86: '86_Paperboy', 87: '87_Paperboy_2', 88: '88_Bionic_Commando', 89: '89_Ninja_Ryukenden_GB_Matenrou_Kessen', 90: '90_Miracle_Adventure_of_Esparks_-_Ushinawareta_Seiseki_Perivron', 91: '91_Nettou_Toushinden', 92: '92_Go_Go_Ackman', 93: '93_Teenage_Mutant_Ninja_Turtles', 94: '94_Parodius_Da!', 95: '95_Alfred_Chicken_(1993)', 96: '96_Nettou_World_Heroes_2_Jet', 97: '97_Crystal_Quest', 98: '98_Retroid_(Homebrew)', 99: '99_Felix_the_Cat', 100: '100_Battle_Ping_Pong', 101: '101_Mogura_de_Pon!', 102: \"102_George_Foreman's_KO_Boxing\", 103: '103_Magical_Taruruuto-kun', 104: '104_Nettou_Garou_Densetsu_2', 105: '105_Goal!', 106: '106_Magnetic_Soccer', 107: '107_Pang', 108: '108_Gluecksrad', 109: '109_The_Little_Mermaid', 110: \"110_Mickey's_Dangerous_Chase\", 111: '111_Boxing', 112: '112_Kyoro-chan_Land', 113: '113_Pingu:_Sekai_de_Ichiban_Genki_na_Penguin', 114: '114_Lemmings_2:_The_Tribes_(Prototype)', 115: '115_Fish_Dude', 116: '116_Penguin_Wars', 117: '117_Micro_Machines_2:_Turbo_Tournament', 118: '118_Superman', 119: '119_Cliffhanger', 120: '120_Mighty_Morphin_Power_Rangers:_The_Movie', 121: '121_Taz-Mania_2', 122: '122_Castelian', 123: '123_Taz-Mania', 124: '124_Speedy_Gonzales', 125: \"125_Snoopy's_Magic_Show\", 126: '126_Lemmings', 127: '127_Batman:_The_Animated_Series', 128: '128_Lucky_Monkey', 129: \"129_Mickey's_Ultimate_Challenge\", 130: '130_Lunar_Lander', 131: '131_Missile_Command', 132: '132_Looney_Tunes', 133: '133_Akumajou_Special:_Boku_Dracula-kun', 134: '134_Akumajou_Dracula:_Shikkokutaru_Zensoukyoku', 135: '135_Dracula_Densetsu_II', 136: '136_Asterix_&_Obelix', 137: '137_Dracula_Densetsu', 138: '138_The_Getaway', 139: '139_Lamborghini_American_Challenge', 140: '140_The_Amazing_Spider-Man', 141: '141_Joe_&_Mac:_Caveman_Ninja', 142: '142_Kuusou_Kagaku_Sekai_Gulliver_Boy:_Kuusou_Kagaku_Puzzle_Purittopon!!', 143: '143_Money_Idol_Exchanger', 144: \"144_Lock_'n'_Chase\", 145: '145_Dead_Heat_Scramble', 146: '146_Max', 147: '147_Un_Indien_dans_la_Ville', 148: '148_Choplifter_II:_Rescue_Survive', 149: '149_The_Adventures_of_Star_Saver', 150: '150_Capcom_Quiz:_Hatena_no_Daibouken', 151: '151_Hero_Shuugou!!_Pinball_Party', 152: '152_Kamen_Rider_SD:_Hashire!_Mighty_Riders', 153: '153_Battle_Unit_Zeoth', 154: '154_Fist_of_the_North_Star:_10_Big_Brawls_for_the_King_of_the_Universe', 155: '155_Dirty_Racing', 156: \"156_Kirby's_Dream_Land\", 157: '157_Astro_Rabby', 158: '158_Ganso!!_Yancha_Maru', 159: '159_Street_Fighter_II', 160: '160_The_Simpsons:_Bart_vs._The_Juggernauts', 161: '161_Pocket_Bomberman', 162: '162_Chase_H.Q.', 163: '163_Operation_C', 164: '164_Chikyu_Kaiho_Gun_ZAS', 165: '165_Hokuto_no_Ken:_Seizetsu_Juuban_Shoubu', 166: '166_Final_Fantasy_Adventure', 167: '167_Zool', 168: '168_Daiku_no_Gen-san:_Robot_Teikoku_no_Yabou', 169: \"169_Tail'Gator\", 170: '170_Daiku_no_Gen-san:_Ghost_Building_Company', 171: '171_Batman:_Return_of_the_Joker', 172: '172_Star_Trek:_25th_Anniversary', 173: '173_Gekitou_Power_Modeller', 174: '174_Terminator_2:_The_Arcade_Game', 175: '175_Heiankyo_Alien', 176: '176_Head-On', 177: '177_Zoids_Densetsu', 178: \"178_Gargoyle's_Quest\", 179: '179_Captain_America_and_the_Avengers', 180: \"180_Kirby's_Block_Ball\", 181: '181_IndestructoTank!_(Unlicensed)', 182: '182_Chiki_Chiki_Tengoku', 183: \"183_Disney's_Toy_Story\", 184: '184_After_Burst', 185: '185_G-Zero_(Homebrew)', 186: '186_Tumble_Pop', 187: '187_Gunship_(Unlicensed)', 188: '188_Balloon_Kid', 189: '189_Master_Karateka', 190: '190_Genesis_(Unlicensed)', 191: '191_TwinBee_da!!', 192: '192_Black_Castle_(Homebrew)', 193: '193_Avenging_Spirit', 194: '194_Block_Kuzushi_GB', 195: '195_Contra_Spirits', 196: \"196_Kirby's_Dream_Land_2\", 197: '197_A_Fairy_Without_Wings_(Homebrew)', 198: '198_Bishoujo_Senshi_Sailormoon_R', 199: \"199_Kirby's_Pinball_Land\", 200: '200_Contra', 201: '201_Baby_T-Rex', 202: '202_Spot', 203: '203_Kid_Icarus:_Of_Myths_and_Monsters', 204: '204_Trip_World', 205: '205_Riddick_Bowe_Boxing', 206: '206_Bamse', 207: '207_Super_R.C._Pro-AM', 208: '208_Agro_Soar', 209: \"209_Mickey's_Chase\", 210: '210_Pinball:_Revenge_of_the_Gator', 211: '211_Initial_D_Gaiden', 212: '212_Worms', 213: '213_The_New_Chessmaster', 214: '214_The_Simpsons:_Bart_&_the_Beanstalk', 215: '215_Real_Bout_Special', 216: '216_The_Chessmaster', 217: '217_McDonaldland', 218: '218_Battle_Arena_Toshinden', 219: '219_The_Lost_World:_Jurassic_Park', 220: '220_Super_Hunchback', 221: '221_World_Heroes_2_Jet', 222: \"222_We're_Back!:_A_Dinosaur's_Story\", 223: '223_Killer_Instinct', 224: '224_Bomber_King:_Scenario_2', 225: '225_Nemesis_II:_The_Return_of_the_Hero', 226: '226_Donkey_Kong_Land_2', 227: \"227_Muhammad_Ali's_Boxing\", 228: '228_Nemesis', 229: '229_True_Lies', 230: '230_The_Humans', 231: \"231_The_Legend_of_Zelda:_Link's_Awakening_(1993)\", 232: '232_Super_Mario_Land_2:_6_Golden_Coins', 233: '233_Teenage_Mutant_Ninja_Turtles_III:_Radical_Rescue', 234: '234_Kung-Fu_Master', 235: '235_Blaster_Master_Jr.', 236: '236_Best_of_the_Best:_Championship_Karate', 237: '237_Kid_Dracula', 238: '238_Pokemon_Green_(Fan_Translation)', 239: '239_Vattle_Giuce', 240: '240_Bubble_Ghost', 241: '241_Game_&_Watch_Gallery', 242: '242_Deadeus_(Homebrew)', 243: '243_Banishing_Racer', 244: '244_Donkey_Kong_Land', 245: '245_Magipanels_(Homebrew)', 246: '246_Contra:_The_Alien_Wars', 247: '247_Pokemon_Blue', 248: '248_Alien_vs_Predator:_The_Last_of_His_Clan', 249: '249_Mortal_Kombat_3', 250: '250_Alien_vs_Predator:_The_Last_of_His_Clan', 251: '251_Daffy_Duck:_The_Marvin_Missions', 252: '252_Mortal_Kombat_II', 253: '253_Blaster_Master_Boy', 254: '254_Prince_of_Persia', 255: '255_Mortal_Kombat', 256: '256_Amazing_Penguin', 257: \"257_Bill_&_Ted's_Excellent_Game_Boy_Adventure\", 258: '258_Universal_Soldier', 259: '259_Bionic_Battler', 260: '260_The_Addams_Family', 261: \"261_Castlevania_II:_Belmont's_Revenge\", 262: '262_Double_Dragon_III:_The_Arcade_Game', 263: '263_The_Blues_Brothers', 264: '264_Castlevania_Legends', 265: '265_Double_Dragon_II', 266: '266_The_Rugrats_Movie', 267: '267_Double_Dragon', 268: '268_Teenage_Mutant_Ninja_Turtles_II:_Back_from_the_Sewers', 269: '269_The_Incredible_Crash_Dummies', 270: '270_Tennis', 271: '271_Battle_Bull', 272: '272_The_Blues_Brothers:_Jukebox_Adventure', 273: '273_Ninja_Gaiden_Shadow', 274: '274_Altered_Space:_A_3-D_Alien_Adventure', 275: '275_Teenage_Mutant_Ninja_Turtles:_Fall_of_the_Foot_Clan', 276: '276_Gremlins_2:_The_New_Batch', 277: '277_Beetlejuice', 278: '278_Desert_Strike:_Return_to_the_Gulf', 279: \"279_Disney's_DuckTales_2\", 280: '280_Burai_Fighter_Deluxe', 281: '281_R-Type_II', 282: \"282_Disney's_DuckTales\", 283: '283_X', 284: \"284_The_Addams_Family:_Pugsley's_Scavenger_Hunt\", 285: '285_R-Type', 286: '286_Mega_Man_V', 287: '287_Total_Carnage', 288: '288_Asterix', 289: '289_Pokemon_Red', 290: '290_Super_James_Pond', 291: '291_Mega_Man_IV', 292: '292_Metroid_II:_Return_of_Samus', 293: '293_Battle_Crusher', 294: '294_Castlevania:_The_Adventure', 295: '295_Mega_Man_III', 296: '296_Tekkyu_Fight!_The_Great_Battle_Gaiden', 297: '297_F-1_Race', 298: '298_Mega_Man_II', 299: \"299_Disney's_Aladdin\", 300: '300_Turrican', 301: \"301_Mega_Man:_Dr._Wily's_Revenge\", 302: '302_Jurassic_Park_Part_2:_The_Chaos_Continues', 303: '303_Solar_Striker', 304: '304_Jurassic_Park', 305: '305_Bomberman_GB_(JP)', 306: \"306_Disney's_The_Lion_King\", 307: '307_Spiritual_Warfare_(Unlicensed)', 308: '308_Super_Mario_Land_3:_Wario_Land', 309: '309_Wizards_&_Warriors_X:_Fortress_of_Fear', 310: \"310_Disney's_TaleSpin\", 311: '311_Dig_Dug', 312: '312_Cosmo_Tank_(JP)', 313: '313_Donkey_Kong', 314: \"314_Disney's_Pinocchio\", 315: '315_Super_Mario_Land', 316: '316_Cosmo_Tank', 317: '317_The_Flash', 318: '318_Rockman_8_(Unlicensed)', 319: '319_Dick_Tracy', 320: '320_Phantasm', 321: '321_Swamp_Thing', 322: '322_Bubble_Bobble_Part_2', 323: \"323_Wayne's_World\", 324: '324_Indiana_Jones_and_the_Last_Crusade', 325: '325_Tetris', 326: '326_Casper', 327: \"327_MTV's_Beavis_and_Butt-Head\", 328: '328_Mystical_Ninja_starring_Goemon', 329: '329_Garfield_Labyrinth', 330: \"330_Pop'n_Twinbee\", 331: '331_Hugo_2_(Fan_Translation)', 332: '332_Hugo', 333: '333_Star_Hawk', 334: '334_Battle_Dodge_Ball', 335: \"335_Tiny_Toon_Adventures:_Babs'_Big_Break\", 336: '336_Mr._Do!', 337: '337_Hoshi_no_Kirby', 338: '338_Xenon_2', 339: '339_Toxic_Crusaders', 340: '340_BreakThru!', 341: '341_Pac-In-Time', 342: '342_Mickey_Mouse:_Magic_Wands!', 343: '343_Mickey_Mouse_V', 344: '344_Top_Ranking_Tennis', 345: '345_Wario_Blast:_Featuring_Bomberman!', 346: '346_Mighty_Morphin_Power_Rangers', 347: '347_Kirby_no_Pinball', 348: '348_Heavyweight_Championship_Boxing', 349: '349_Tasmania_Monogatari', 350: '350_Super_Mario_4_(Unlicensed)', 351: '351_Mr._Nutz', 352: '352_Crayon_Shin-chan_4_-_Ora_no_Itazura_Daihenshin', 353: '353_Mickey_Mouse_II', 354: '354_Mickey_Mouse_IV:_Mahou_no_Labyrinth', 355: '355_Bust-A-Move_2_Arcade_Edition', 356: '356_Ms._Pac-Man', 357: '357_Bust-A-Move_3_DX', 358: \"358_Bram_Stoker's_Dracula\", 359: '359_Mercenary_Force', 360: '360_Last_Action_Hero', 361: '361_SD_Hiryuu_no_Ken_Gaiden', 362: '362_RoboCop', 363: '363_Mickey_Mouse', 364: '364_Shadow_Warriors', 365: '365_Lethal_Weapon', 366: '366_Kenyuu_Densetsu_Yaiba', 367: '367_Raging_Fighter', 368: '368_Cool_Spot', 369: '369_Snow_Bros._Jr.', 370: '370_Zoop', 371: '371_Navy_Seals', 372: '372_Gradius:_The_Interstellar_Assault', 373: '373_The_Flintstones:_King_Rock_Treasure_Island', 374: '374_Lucky_Luke', 375: \"375_Maru's_Mission\", 376: '376_The_Adventures_of_Tintin:_Prisoners_of_the_Sun', 377: \"377_Battletoads_in_Ragnarok's_World\", 378: '378_Tintin_in_Tibet', 379: \"379_Bonk's_Revenge\", 380: '380_Robocop_2_(JP)', 381: \"381_Bonk's_Adventure\", 382: '382_Oira_Jajamaru!_Sekai_Daibouken', 383: '383_Samurai_Shodown', 384: '384_Heisei_Tensai_Bakabon', 385: '385_Jankenman', 386: '386_The_Punisher:_The_Ultimate_Payback', 387: '387_Motocross_Maniacs', 388: '388_Tetris_Attack', 389: '389_Prehistorik_Man', 390: \"390_Spider-Man_and_the_X-Men_in_Arcade's_Revenge\", 391: '391_Sagaia', 392: '392_Robocop_2', 393: '393_Battletoads_&_Double_Dragon:_The_Ultimate_Team', 394: '394_Volley_Fire', 395: '395_Battletoads', 396: '396_Itchy_&_Scratchy:_Miniature_Golf_Madness', 397: '397_Probotector_2', 398: \"398_Boomer's_Adventure_in_ASMIK_World\", 399: '399_Darkman', 400: '400_Probotector', 401: '401_Darkwing_Duck', 402: '402_Super_Scrabble', 403: '403_Terminator_2:_Judgment_Day', 404: '404_Rockman_World_3', 405: '405_Saigo_no_Nindou', 406: '406_Pit_Fighter', 407: '407_Rockman_World_2', 408: '408_Sanrio_Carnival_(Fan_Translation)', 409: '409_Quarth', 410: '410_The_Pagemaster', 411: '411_Pinball_Dreams', 412: '412_Micro_Machines', 413: '413_Game_Boy_Gallery_(EU)', 414: \"414_Yoshi's_Cookie\", 415: '415_Ikari_no_Yousai_2', 416: '416_Taiyou_no_Yuusha_Fighbird_GB_(Fan_Translation)', 417: '417_Ikari_no_Yousai', 418: '418_Rockman_World', 419: '419_Parodius', 420: '420_Super_Off_Road', 421: '421_Marble_Madness', 422: '422_Buster_Brothers', 423: '423_Taito_Chase_H.Q.', 424: '424_Pinball:_66-hiki_no_Wani_Daikoushin', 425: '425_Taiyou_no_Yuusha_Fighbird_GB', 426: '426_Pac-Man', 427: '427_Aero_Star', 428: '428_Beethoven', 429: '429_Chuck_Rock', 430: '430_Cutthroat_Island', 431: '431_Bomb_Jack', 432: '432_The_Smurfs', 433: '433_Asteroids', 434: '434_Banishing_Racer_(Fan_Translation)', 435: '435_Adventure_Island_II_-_Aliens_in_Paradise', 436: '436_The_Amazing_Spider-Man_2', 437: '437_Adventure_Island', 438: '438_Teenage_Mutant_Ninja_Turtles_3:_Turtles_Kiki_Ippatsu', 439: \"439_Hammerin'_Harry:_Ghost_Building_Company\", 440: '440_Teenage_Mutant_Hero_Turtles_III:_Radical_Rescue', 441: '441_Q-Bert', 442: '442_Teenage_Mutant_Hero_Turtles_II:_Back_from_the_Sewers', 443: '443_The_Kick_Boxing', 444: '444_Space_Invaders', 445: \"445_Nettou_King_of_Fighters_'97_(Unlicensed)\", 446: \"446_Nettou_King_of_Fighters_'96\", 447: '447_Spirou', 448: '448_The_Battle_of_Olympus', 449: '449_Alleyway', 450: '450_Teenage_Mutant_Hero_Turtles:_Fall_of_the_Foot_Clan', 451: \"451_Nettou_King_of_Fighters_'95\", 452: '452_Looney_Tunes:_Bugs_Bunny_to_Yukai_na_Nakama-tachi', 453: '453_Centipede', 454: '454_Magical_Taruruuto-kun_2:_Raibaa_Zone_Panic!!', 455: '455_Hugo_2', 456: '456_Tetris_Plus', 457: '457_Primal_Rage', 458: '458_Fortified_Zone', 459: '459_Totsugeki!_Ponkotsu_Tank', 460: '460_The_Flintstones', 461: '461_Joe_&_Mac', 462: '462_Batman:_The_Videogame', 463: '463_Dynablaster', 464: '464_X_(Fan_Translation)', 465: '465_Monopoly', 466: '466_Dr._Mario', 467: '467_Downtown_Nekketsu_Koushinkyoku:_Dokodemo_Daiundouka', 468: '468_Bubble_Bobble', 469: '469_Frogger', 470: \"470_Bart_Simpson's_Escape_from_Camp_Deadly\", 471: '471_Rampart', 472: '472_Spot:_The_Cool_Adventure', 473: '473_Speedball_2', 474: '474_Qix', 475: '475_Earthworm_Jim', 476: '476_The_Ren_&_Stimpy_Show:_Space_Cadet_Adventures', 477: '477_Booby_Boys_(Fan_Translation)', 478: '478_Tetris_Blast', 479: '479_Booby_Boys', 480: '480_Shaq_Fu', 481: '481_Battle_City', 482: '482_The_Final_Fantasy_Legend', 483: '483_Story_of_Lasama_(Unlicensed)', 484: '484_Super_Star_Wars:_Return_of_the_Jedi', 485: '485_Star_Wars:_The_Empire_Strikes_Back', 486: '486_Tasmania_Story', 487: '487_Parasol_Stars:_The_Story_of_Bubble_Bobble_III', 488: '488_Waterworld'}\n"
     ]
    }
   ],
   "source": [
    "print(id_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_mkv_to_mp4(input_path: str,\n",
    "                            semaphore: asyncio.Semaphore,\n",
    "                            output_path):\n",
    "    \"\"\"\n",
    "    Async function to convert MKV file to MP4 using FFmpeg.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input MKV file\n",
    "        output_path: Path for output MP4 file (optional)\n",
    "        semaphore: Asyncio semaphore for controlling concurrent conversions\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if conversion was successful\n",
    "    \"\"\"\n",
    "    async def run_ffmpeg(stream):\n",
    "        loop = asyncio.get_event_loop()\n",
    "        await loop.run_in_executor(None, lambda: ffmpeg.run(stream, overwrite_output=True))\n",
    "\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            input_path = Path(input_path)\n",
    "            if not input_path.exists():\n",
    "                raise FileNotFoundError(f\"Input file not found: {input_path}\")\n",
    "                \n",
    "            output_path_final = Path(output_path) if output_path else input_path.with_suffix('.mp4')\n",
    "            \n",
    "            try:\n",
    "                # Try stream copy first (fast)\n",
    "                stream = ffmpeg.input(str(input_path))\n",
    "                stream = ffmpeg.output(stream, str(output_path_final),\n",
    "                                     vcodec='copy',\n",
    "                                     acodec='copy',\n",
    "                                     loglevel='error')\n",
    "                await run_ffmpeg(stream)\n",
    "                \n",
    "            except ffmpeg.Error:\n",
    "                # If stream copy fails, try re-encoding\n",
    "                stream = ffmpeg.input(str(input_path))\n",
    "                stream = ffmpeg.output(stream, str(output_path_final),\n",
    "                                     vcodec='libx264',\n",
    "                                     acodec='aac',\n",
    "                                     loglevel='error')\n",
    "                await run_ffmpeg(stream)\n",
    "                \n",
    "        except ffmpeg.Error as e:\n",
    "            print(f\"Conversion failed: {e.stderr.decode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoGen\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd gameboy_longplays/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"longplay_mp4_files\" && for f in *.mkv; do ffmpeg -i \"$f\" -c copy \"longplay_mp4_files/${f%.mkv}.mp4\"; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp *.mp4 longplay_mp4_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd gameboy_longplays/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {}\n",
    "for file in Path('.').glob('*'):\n",
    "    idx = int(file.name.split('_')[0])\n",
    "    file_idx = int(file.name.split('_')[1])\n",
    "    if ids.get(idx, None) is not None:\n",
    "        ids[idx] += 1\n",
    "    else:\n",
    "        ids[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for lp in lp_data['longplays']:\n",
    "    if ids[int(lp['id'])] < len(lp['archive_links']):\n",
    "        error.append(lp['archive_links'][ids[lp['id']]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
