{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videogamegen.data.chunkstore import ChunkStore\n",
    "import h5py\n",
    "import lzf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/VideoGen\n"
     ]
    }
   ],
   "source": [
    "%cd VideoGen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = ChunkStore('data/chunkstore/0.0', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = store[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'byte_offset': 0, 'byte_size': 5297, 'shape': (256, 256, 1), 'dtype': 'uint8'}\n"
     ]
    }
   ],
   "source": [
    "print(store.get_metadata(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_byte_size = np.prod(store.get_metadata(0)['shape']) * np.dtype(store.get_metadata(0)['dtype']).itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65536\n"
     ]
    }
   ],
   "source": [
    "print(original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dset.shape: (122413, 256, 256, 1)\n",
      "dset.chunks: (1, 256, 256, 1)\n",
      "Original frame shape: (5, 256, 256, 1)\n",
      "Original frame dtype: uint8\n",
      "Original frame size in bytes: 327680\n",
      "Compressed size: 26475\n",
      "Decompressed size: 327680\n",
      "Reconstructed frame shape: (5, 256, 256, 1)\n",
      "Data matches: True\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/longplay_h5_files/0_0.h5', 'r') as f:\n",
    "    dset = f['video_frames']\n",
    "    print(f\"dset.shape: {dset.shape}\")\n",
    "    print(f\"dset.chunks: {dset.chunks}\")\n",
    "\n",
    "    frame = dset[0:5]\n",
    "    print(f\"Original frame shape: {frame.shape}\")\n",
    "    print(f\"Original frame dtype: {frame.dtype}\")\n",
    "    print(f\"Original frame size in bytes: {frame.nbytes}\")\n",
    "    \n",
    "    # Compress\n",
    "    compressed = lzf.compress(frame.tobytes())\n",
    "    print(f\"Compressed size: {len(compressed)}\")\n",
    "    \n",
    "    # Try to decompress\n",
    "    original_size = frame.nbytes\n",
    "    decompressed = lzf.decompress(compressed, original_size)\n",
    "    print(f\"Decompressed size: {len(decompressed)}\")\n",
    "    \n",
    "    # Try to reconstruct the array\n",
    "    reconstructed = np.frombuffer(decompressed, dtype=frame.dtype).reshape(frame.shape)\n",
    "    print(f\"Reconstructed frame shape: {reconstructed.shape}\")\n",
    "    \n",
    "    # Verify data is the same\n",
    "    print(f\"Data matches: {np.array_equal(frame, reconstructed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw stored data:\n",
      "Size: 5297\n",
      "First 20 bytes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "with ChunkStore('data/chunkstore/0.0', 'r') as store:\n",
    "    metadata = store.chunks_metadata[0]\n",
    "    raw_bytes = store.mmap[metadata.byte_offset:metadata.byte_offset + metadata.byte_size].tobytes()\n",
    "    print(\"Raw stored data:\")\n",
    "    print(f\"Size: {len(raw_bytes)}\")\n",
    "    print(f\"First 20 bytes: {list(raw_bytes[:20])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_write_process():\n",
    "    \"\"\"Inspect each step of writing data to the ChunkStore.\"\"\"\n",
    "    with h5py.File('data/longplay_h5_files/0_0.h5', 'r') as f:\n",
    "        dset = f['video_frames']\n",
    "        frame = dset[0]\n",
    "        \n",
    "        # 1. Check original frame\n",
    "        print(\"1. Original Frame:\")\n",
    "        print(f\"Shape: {frame.shape}\")\n",
    "        print(f\"Type: {frame.dtype}\")\n",
    "        print(f\"First few values: {frame.flatten()[:10]}\")\n",
    "        \n",
    "        # 2. Convert to bytes\n",
    "        frame_bytes = frame.tobytes()\n",
    "        print(\"\\n2. Frame as bytes:\")\n",
    "        print(f\"Size: {len(frame_bytes)}\")\n",
    "        print(f\"First 20 bytes: {list(frame_bytes[:20])}\")\n",
    "        \n",
    "        # 3. Compress\n",
    "        compressed = lzf.compress(frame_bytes)\n",
    "        print(\"\\n3. After compression:\")\n",
    "        print(f\"Size: {len(compressed)}\")\n",
    "        print(f\"First 20 bytes: {list(compressed[:20])}\")\n",
    "        \n",
    "        # 4. Write to mmap file directly\n",
    "        print(\"\\n4. Writing to mmap file:\")\n",
    "        mmap_path = \"test_mmap.bin\"\n",
    "        mmap_size = len(compressed)\n",
    "        \n",
    "        # Try different writing methods\n",
    "        print(\"\\nMethod 1: Direct numpy memmap:\")\n",
    "        mmap = np.memmap(mmap_path, dtype='uint8', mode='w+', shape=(mmap_size,))\n",
    "        np.copyto(mmap, np.frombuffer(compressed, dtype='uint8'))\n",
    "        mmap.flush()\n",
    "        del mmap  # Force flush and close\n",
    "        \n",
    "        # Read back and verify\n",
    "        print(\"\\n5. Reading back:\")\n",
    "        with open(mmap_path, 'rb') as f:\n",
    "            read_data = f.read()\n",
    "        print(f\"Read size: {len(read_data)}\")\n",
    "        print(f\"First 20 bytes: {list(read_data[:20])}\")\n",
    "        print(f\"Data matches original compressed: {read_data == compressed}\")\n",
    "        \n",
    "        # Try direct file write for comparison\n",
    "        print(\"\\nMethod 2: Direct file write:\")\n",
    "        with open(\"test_direct.bin\", 'wb') as f:\n",
    "            f.write(compressed)\n",
    "        \n",
    "        with open(\"test_direct.bin\", 'rb') as f:\n",
    "            direct_read = f.read()\n",
    "        print(f\"Direct write size: {len(direct_read)}\")\n",
    "        print(f\"First 20 bytes: {list(direct_read[:20])}\")\n",
    "        print(f\"Data matches original compressed: {direct_read == compressed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Original Frame:\n",
      "Shape: (256, 256, 1)\n",
      "Type: uint8\n",
      "First few values: [255 255 255 255 255 255 255 255 255 255]\n",
      "\n",
      "2. Frame as bytes:\n",
      "Size: 65536\n",
      "First 20 bytes: [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255]\n",
      "\n",
      "3. After compression:\n",
      "Size: 5297\n",
      "First 20 bytes: [1, 255, 255, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255]\n",
      "\n",
      "4. Writing to mmap file:\n",
      "\n",
      "Method 1: Direct numpy memmap:\n",
      "\n",
      "5. Reading back:\n",
      "Read size: 5297\n",
      "First 20 bytes: [1, 255, 255, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255]\n",
      "Data matches original compressed: True\n",
      "\n",
      "Method 2: Direct file write:\n",
      "Direct write size: 5297\n",
      "First 20 bytes: [1, 255, 255, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255, 0, 224, 255]\n",
      "Data matches original compressed: True\n"
     ]
    }
   ],
   "source": [
    "inspect_write_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
