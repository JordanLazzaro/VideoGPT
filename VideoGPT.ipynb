{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM-sO50_MNBM"
      },
      "outputs": [],
      "source": [
        "!pip install -q wandb pytorch_lightning av"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2bkr0JVXBgxw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_lightning as pl\n",
        "from torchvision.datasets.video_utils import VideoClips\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import Compose, Lambda, Resize, ToTensor, CenterCrop, Grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCCwpzdaEHw9",
        "outputId": "6faaa634-d8a2-4596-93f7-820b2885c312"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "steamboat_willie_path = '/content/drive/My Drive/SteamboatWillie.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1AMOdC0FLCM",
        "outputId": "91c5cc7f-e91a-4419-e4f3-22d498051ec4"
      },
      "outputs": [],
      "source": [
        "class SteamboatWillieDataset(Dataset):\n",
        "    def __init__(self, paths, clip_length=16):\n",
        "        super().__init__()\n",
        "        self.video_clips = VideoClips(\n",
        "            paths,\n",
        "            clip_length_in_frames=clip_length,\n",
        "            frames_between_clips=clip_length,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        self.transforms = Compose([\n",
        "            Lambda(lambda x: x.permute(0, 3, 1, 2)),     # (T, H, W, C) to (T, C, H, W) for Greyscale\n",
        "            Grayscale(num_output_channels=1),            # Convert to grayscale\n",
        "            Lambda(lambda x: x.permute(1, 0, 2, 3)),     # (T, C, H, W) to (C, T, H, W) for Conv3d\n",
        "            Lambda(lambda x: CenterCrop((480, 575))(x)), # Center crop to remove virtical bars\n",
        "            Lambda(lambda x: Resize((256, 256))(x)),     # Resize frames\n",
        "            Lambda(lambda x: x / 255.),                  # Scale pixel values to [0, 1]\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        print(f'len: {self.video_clips.num_clips()}')\n",
        "        return self.video_clips.num_clips()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        print(f'getting idx: {idx}')\n",
        "        try:\n",
        "            clip, _, _, _ = self.video_clips.get_clip(idx)\n",
        "            return self.transforms(clip)\n",
        "        except:\n",
        "            print(f'error getting idx: {idx}')\n",
        "\n",
        "\n",
        "class SteamboatWillieDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, paths, batch_size=32, train_split=0.8):\n",
        "        super().__init__()\n",
        "        self.paths = paths\n",
        "        self.batch_size = batch_size\n",
        "        self.train_split = train_split\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.full_dataset = SteamboatWillieDataset(self.paths)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            train_len = int(len(self.full_dataset) * self.train_split)\n",
        "            val_len = len(self.full_dataset) - train_len\n",
        "            self.train_dataset, self.val_dataset = random_split(self.full_dataset, [train_len, val_len])\n",
        "            print(f'Train: {len(self.train_dataset)}, Val: {len(self.val_dataset)}')\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_module = SteamboatWillieDataModule([steamboat_willie_path])\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "\n",
        "train_loader = data_module.train_dataloader()\n",
        "val_loader = data_module.val_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_batch = next(iter(train_loader)) # segfaulting with more than 0 workers"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
